{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0,1,2,3'\n",
    "\n",
    "labels_root = './../../EAGER/data'\n",
    "frames_root = './../../../../data'\n",
    "export_dir = './tfrecords/'\n",
    "organized_dir = export_dir + 'organized'\n",
    "video_dir = './videos/'\n",
    "\n",
    "import calharmony_data\n",
    "dataset = calharmony_data.Dataset(labels_root, frames_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:21:20 root INFO: Loading 2 participant directories.\n",
      "14:21:20 root INFO: Working on P429-2020_03_03-07\n",
      "14:21:20 root INFO: Dataset file already exists. Skipping <built-in function id>.\n",
      "14:21:20 root INFO: Working on P429-2020_03_03-08\n",
      "14:21:20 root INFO: Dataset file already exists. Skipping <built-in function id>.\n",
      "14:21:20 root INFO: Working on P429-2020_03_03-09\n",
      "14:21:20 root INFO: Dataset file already exists. Skipping <built-in function id>.\n",
      "14:21:20 root INFO: Working on P429-2020_03_04-05\n",
      "14:21:20 root INFO: Dataset file already exists. Skipping <built-in function id>.\n",
      "14:21:20 root INFO: Working on P429-2020_03_04-10\n",
      "14:21:20 root INFO: Dataset file already exists. Skipping <built-in function id>.\n",
      "14:21:20 root INFO: Working on P429-2020_03_04-12\n",
      "14:21:20 root INFO: Dataset file already exists. Skipping <built-in function id>.\n",
      "14:21:20 root INFO: Working on P429-2020_03_05-06\n",
      "14:21:20 root INFO: Dataset file already exists. Skipping <built-in function id>.\n",
      "14:21:20 root INFO: Working on P429-2020_03_05-11\n",
      "14:21:20 root INFO: Dataset file already exists. Skipping <built-in function id>.\n",
      "14:21:20 root INFO: Working on P431-2020_03_12-09\n",
      "14:21:20 root INFO: Dataset file already exists. Skipping <built-in function id>.\n",
      "14:21:20 root INFO: Working on P431-2020_03_12-10\n",
      "14:21:20 root INFO: Dataset file already exists. Skipping <built-in function id>.\n",
      "14:21:20 root INFO: Working on P431-2020_03_12-11\n",
      "14:21:20 root INFO: Dataset file already exists. Skipping <built-in function id>.\n",
      "14:21:20 root INFO: Working on P431-2020_03_12-12\n",
      "14:21:20 root INFO: Dataset file already exists. Skipping <built-in function id>.\n",
      "14:21:20 root INFO: Done\n",
      "14:21:20 root INFO: Finished converting the dataset!\n"
     ]
    }
   ],
   "source": [
    "import main as runner\n",
    "runner.main(dataset, labels_root, frames_root, export_dir, video_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:21:20 root INFO: 8 train .tfrecords\n",
      "14:21:20 root INFO: 4 test .tfrecords\n",
      "14:21:20 root INFO: ./tfrecords/organized/train/P429-2020_03_05-06.tfrecord already exists. No need to copy!\n",
      "14:21:20 root INFO: ./tfrecords/organized/train/P429-2020_03_04-05.tfrecord already exists. No need to copy!\n",
      "14:21:20 root INFO: ./tfrecords/organized/train/P429-2020_03_04-10.tfrecord already exists. No need to copy!\n",
      "14:21:20 root INFO: ./tfrecords/organized/train/P429-2020_03_03-08.tfrecord already exists. No need to copy!\n",
      "14:21:20 root INFO: ./tfrecords/organized/train/P429-2020_03_04-12.tfrecord already exists. No need to copy!\n",
      "14:21:20 root INFO: ./tfrecords/organized/train/P429-2020_03_03-07.tfrecord already exists. No need to copy!\n",
      "14:21:20 root INFO: ./tfrecords/organized/train/P429-2020_03_03-09.tfrecord already exists. No need to copy!\n",
      "14:21:20 root INFO: ./tfrecords/organized/train/P429-2020_03_05-11.tfrecord already exists. No need to copy!\n",
      "14:21:20 root INFO: ./tfrecords/organized/test/P431-2020_03_12-09.tfrecord already exists. No need to copy!\n",
      "14:21:20 root INFO: ./tfrecords/organized/test/P431-2020_03_12-11.tfrecord already exists. No need to copy!\n",
      "14:21:20 root INFO: ./tfrecords/organized/test/P431-2020_03_12-12.tfrecord already exists. No need to copy!\n",
      "14:21:20 root INFO: ./tfrecords/organized/test/P431-2020_03_12-10.tfrecord already exists. No need to copy!\n",
      "14:21:20 root INFO: Done organising\n"
     ]
    }
   ],
   "source": [
    "from data_organiser import DataOrganiser\n",
    "organiser = DataOrganiser(dataset, src_dir=export_dir, organised_dir=organized_dir)\n",
    "organiser.organise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r ./tfrecords/organized/ ./../deep-intake-detection/tf-records/\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
